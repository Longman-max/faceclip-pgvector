{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g04OdKntfzG5"
      },
      "source": [
        "# Image recognition with Python, OpenCV, OpenAI CLIP model and PostgreSQL `pgvector`\n",
        "\n",
        "This repository contains the working code for the example in the [blog post](https://aiven.io/developer/find-faces-with-pgvector)\n",
        "\n",
        "The below is the overall flow:\n",
        "\n",
        "![Overall flow](https://github.com/Aiven-Labs/pgvector-image-recognition/blob/main/entire_flow.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc9dGsKbfzG6"
      },
      "source": [
        "## Step 0: Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDCW1PT4fzG7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install opencv-python imgbeddings psycopg2-binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCUUUfvufzG7"
      },
      "source": [
        "## Step 1: Face recognition\n",
        "\n",
        "Detect the faces from the [test-image](test-image.png) picture and store them under the `stored-faces` folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PZtR0-5BfzG7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "alg = \"haarcascade_frontalface_default.xml\"\n",
        "# passing the algorithm to OpenCV\n",
        "haar_cascade = cv2.CascadeClassifier(alg)\n",
        "file_name = \"sample.jpeg\"\n",
        "img = cv2.imread(file_name, 0)\n",
        "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "faces = haar_cascade.detectMultiScale(\n",
        "    gray_img, scaleFactor=1.05, minNeighbors=5, minSize=(100, 100)\n",
        ")\n",
        "\n",
        "i = 0\n",
        "for x, y, w, h in faces:\n",
        "    cropped_image = img[y : y + h, x : x + w]\n",
        "    target_file_name = 'stored-faces/' + str(i) + '.jpg'\n",
        "    cv2.imwrite(\n",
        "        target_file_name,\n",
        "        cropped_image,\n",
        "    )\n",
        "    i = i + 1;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL_W_i6MfzG7"
      },
      "source": [
        "## Step 2: Embeddings Calculation\n",
        "\n",
        "Calculate embeddings from the faces and pushing to PostgreSQL, you'll need to change the `<SERVICE_URI>` parameter with the PostgreSQL Service URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X-gDZTU5fzG8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 0.jpg\n",
            "Processed: 1.jpg\n",
            "Processed: 2.jpg\n",
            "Processed: 3.jpg\n",
            "Processed: 4.jpg\n",
            "\n",
            "Total images processed: 5\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Better Face Embeddings using OpenCV's ORB features\n",
        "import numpy as np\n",
        "import cv2\n",
        "import psycopg2\n",
        "import os\n",
        "\n",
        "def get_face_features(img_path):\n",
        "    \"\"\"Extract ORB keypoints and descriptors for face recognition\"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    # Resize to standard size\n",
        "    img = cv2.resize(img, (128, 128))\n",
        "    \n",
        "    # Initialize ORB detector\n",
        "    orb = cv2.ORB_create(nfeatures=100)\n",
        "    \n",
        "    # Find keypoints and descriptors\n",
        "    keypoints, descriptors = orb.detectAndCompute(img, None)\n",
        "    \n",
        "    if descriptors is None:\n",
        "        # Fallback to simple pixel features if no keypoints found\n",
        "        img_flat = img.flatten().astype(float) / 255.0\n",
        "        # Pad or truncate to fixed size\n",
        "        if len(img_flat) > 512:\n",
        "            return img_flat[:512].tolist()\n",
        "        else:\n",
        "            padded = np.pad(img_flat, (0, 512 - len(img_flat)), 'constant')\n",
        "            return padded.tolist()\n",
        "    \n",
        "    # Create fixed-size feature vector from descriptors\n",
        "    # Average all descriptors to get a single 32-dimensional vector\n",
        "    avg_descriptor = np.mean(descriptors, axis=0)\n",
        "    \n",
        "    # Pad to make it larger for better discrimination\n",
        "    feature_vector = np.tile(avg_descriptor, 16)  # 32*16 = 512 dimensions\n",
        "    \n",
        "    return feature_vector.tolist()\n",
        "\n",
        "conn = psycopg2.connect(\"postgres://avnadmin:AVNS_yqlJ6t5_QLrrScUj3gm@pg-57810a8-faces-main.b.aivencloud.com:20861/defaultdb?sslmode=require\")\n",
        "\n",
        "# Create the pictures table with larger vector size\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"DROP TABLE IF EXISTS pictures\")  # Start fresh\n",
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE pictures (\n",
        "        filename TEXT PRIMARY KEY,\n",
        "        embedding vector(512)\n",
        "    )\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "cur.close()\n",
        "\n",
        "processed_count = 0\n",
        "for filename in os.listdir(\"stored-faces\"):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img_path = os.path.join(\"stored-faces\", filename)\n",
        "        embedding = get_face_features(img_path)\n",
        "        \n",
        "        if embedding is not None:\n",
        "            cur = conn.cursor()\n",
        "            cur.execute(\"INSERT INTO pictures values (%s,%s)\", (filename, embedding))\n",
        "            print(f\"Processed: {filename}\")\n",
        "            cur.close()\n",
        "            processed_count += 1\n",
        "\n",
        "conn.commit()\n",
        "print(f\"\\nTotal images processed: {processed_count}\")\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGtjkExFfzG8"
      },
      "source": [
        "## Step 3: Calculate embeddings on a new picture\n",
        "\n",
        "Find the face and calculate the embeddings on the picture `solo-image.png` used for research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7Lu_sRefzG8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculated features for richard.jpg\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Calculate features on a new picture\n",
        "file_name = \"test/richard.jpg\" \n",
        "\n",
        "def get_face_features_from_path(img_path):\n",
        "    \"\"\"Extract ORB keypoints and descriptors for face recognition\"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    # Resize to standard size\n",
        "    img = cv2.resize(img, (128, 128))\n",
        "    \n",
        "    # Initialize ORB detector\n",
        "    orb = cv2.ORB_create(nfeatures=100)\n",
        "    \n",
        "    # Find keypoints and descriptors\n",
        "    keypoints, descriptors = orb.detectAndCompute(img, None)\n",
        "    \n",
        "    if descriptors is None:\n",
        "        # Fallback to simple pixel features if no keypoints found\n",
        "        img_flat = img.flatten().astype(float) / 255.0\n",
        "        # Pad or truncate to fixed size\n",
        "        if len(img_flat) > 512:\n",
        "            return img_flat[:512]\n",
        "        else:\n",
        "            padded = np.pad(img_flat, (0, 512 - len(img_flat)), 'constant')\n",
        "            return padded\n",
        "    \n",
        "    # Create fixed-size feature vector from descriptors\n",
        "    # Average all descriptors to get a single 32-dimensional vector\n",
        "    avg_descriptor = np.mean(descriptors, axis=0)\n",
        "    \n",
        "    # Pad to make it larger for better discrimination\n",
        "    feature_vector = np.tile(avg_descriptor, 16)  # 32*16 = 512 dimensions\n",
        "    \n",
        "    return feature_vector\n",
        "\n",
        "# calculating the features\n",
        "embedding = get_face_features_from_path(file_name)\n",
        "print(f\"Calculated features for {file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRNuACXefzG8"
      },
      "source": [
        "## Step 3: Find similar images by querying the Postgresql database using pgvector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QGS1bkPofzG8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar image:\n",
            "Filename: 4.jpg\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 4: Find similar images by querying the PostgreSQL database using pgvector\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Reconnect to database (connection was closed earlier)\n",
        "conn = psycopg2.connect(\"postgres://avnadmin:AVNS_yqlJ6t5_QLrrScUj3gm@pg-57810a8-faces-main.b.aivencloud.com:20861/defaultdb?sslmode=require\")\n",
        "\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Convert embedding to string format (no [0] since embedding is already the array)\n",
        "string_representation = \"[\"+ \",\".join(str(x) for x in embedding.tolist()) +\"]\"\n",
        "\n",
        "# Query for most similar image\n",
        "cur.execute(\"SELECT * FROM pictures ORDER BY embedding <-> %s LIMIT 1;\", (string_representation,))\n",
        "rows = cur.fetchall()\n",
        "\n",
        "print(\"Most similar image:\")\n",
        "for row in rows:\n",
        "    print(f\"Filename: {row[0]}\")\n",
        "    display(Image(filename=\"stored-faces/\"+row[0]))\n",
        "\n",
        "cur.close()\n",
        "conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
